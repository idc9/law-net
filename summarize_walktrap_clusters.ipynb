{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Walktrap Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify these for your own computer\n",
    "repo_directory = '/Users/Michael/Documents/GitHub/law-net/'\n",
    "\n",
    "data_dir = '/Users/Michael/Desktop/network_data/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cPickle  as pickle\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "\n",
    "# graph package\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "# stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import adjusted_rand_score as ar\n",
    "from sklearn.metrics import calinski_harabaz_score as ch # (X, labels)\n",
    "from sklearn.metrics import completeness_score as cs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import fowlkes_mallows_score as fm\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure as hcvm\n",
    "from sklearn.metrics import homogeneity_score as hs # metric isn't symmetric (labels_true, labels_predicted)\n",
    "from sklearn.metrics import silhouette_score as ss # (X, labels)\n",
    "from sklearn.metrics import silhouette_samples as ss2 # (X, labels)\n",
    "from sklearn.metrics import v_measure_score as vm\n",
    "\n",
    "import scipy.sparse\n",
    "import random\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# our code\n",
    "sys.path.append(repo_directory + 'code/')\n",
    "from summarize_clusters import *\n",
    "from helpful_functions import *\n",
    "\n",
    "sys.path.append(repo_directory + 'vertex_metrics_experiment/code/')\n",
    "from bag_of_words import * \n",
    "\n",
    "# which network to download data for\n",
    "network_name = 'scotus' # 'federal', 'ca1', etc\n",
    "\n",
    "\n",
    "# some sub directories that get used\n",
    "raw_dir = data_dir + 'raw/'\n",
    "subnet_dir = data_dir + network_name + '/'\n",
    "text_dir = subnet_dir + 'textfiles/'\n",
    "nlp_dir = subnet_dir + 'nlp/'\n",
    "nlp_sub_dir = nlp_dir + 'bow_tfidf/' #tfidf matrix (and other info, i.e. vocab) computed from bag-of-words matrix\n",
    "nlp_bow_dir = nlp_dir + 'bow/' #bag-of-words matrix (and other info, i.e. vocab)\n",
    "nlp_df_sub_dir = nlp_dir + 'bow_tfidf_df/'\n",
    "\n",
    "# csv location\n",
    "csv_dir = \"C:/Users/Michael/Documents/GitHub/law-net/csv/\"\n",
    "csv_dir_mod = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_modularity/\"\n",
    "csv_dir_walk = \"C:/Users/Michael/Documents/GitHub/law-net/csv/summarize_walktrap/\"\n",
    "\n",
    "# all the file paths for .txt files\n",
    "file_paths = glob.glob(text_dir + '*.txt')\n",
    "\n",
    "# all opinions\n",
    "all_the_opinions = all_opinions(file_paths)\n",
    "\n",
    "# clusters directory\n",
    "clusters_dir = \"C:/Users/Michael/Desktop/network_data/raw/scotus/clusters/\"\n",
    "\n",
    "# jupyter notebook settings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tf-idf vectors\n",
    "**tfidf_matrix** = (row_index, column_index): tf_idf value (**CSR FORMAT**)  \n",
    "**op_id_to_bow_id** = opinion_id (corresponds to row indices)  \n",
    "**vocab** = all the words in tfidf_matrix (correspond to column indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, op_id_to_bow_id, vocab = load_tf_idf(nlp_sub_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Work:\n",
    "focus on largest connected component of **undirected scotus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the graph\n",
    "G = ig.Graph.Read_GraphML(subnet_dir + network_name +'_network.graphml')\n",
    "\n",
    "# limit ourselves to cases upto and including 2015 since we are missing some textfiles from 2016\n",
    "G = G.subgraph(G.vs.select(year_le=2015))\n",
    "\n",
    "# make graph undirected\n",
    "Gud = G.copy()\n",
    "Gud = Gud.as_undirected()\n",
    "\n",
    "# get largest connected componenet\n",
    "components = Gud.clusters(mode='STRONG')\n",
    "g = components.subgraphs()[np.argmax(components.sizes())]\n",
    "\n",
    "# CL ids of cases in largest connected component\n",
    "CLids = g.vs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## walktrap on undirected scotus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering with 24724 elements and 2264 clusters\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# walktrap clustering\n",
    "cd_walktrap = g.community_walktrap()\n",
    "\n",
    "wt_clust = cd_walktrap.as_clustering()\n",
    "\n",
    "print wt_clust.summary()\n",
    "\n",
    "# save clusters in pandas\n",
    "walktrap_clusters = pd.Series(wt_clust.membership, index=g.vs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 5 biggest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 : 3851 opinions\n",
      "cluster 2 : 2640 opinions\n",
      "cluster 5 : 1996 opinions\n",
      "cluster 3 : 1494 opinions\n",
      "cluster 12 : 1103 opinions\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dict_top_n_clusters = dictionary of top K clusters \n",
    "                      (key=cluster #, value=opinions in cluster)\n",
    "                      \n",
    "biggest_n_clusters = list of top K clusters (int)\n",
    "'''\n",
    "\n",
    "dict_top_n_clusters, biggest_n_clusters = get_top_n_clusters(5, len(wt_clust), walktrap_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Words of Each Cluster\n",
    "This function summarizes a set of opinions by returning the words that appear in these opinions with the highest tf-idf scores.\n",
    "\n",
    "# Top K Words ($\\mu_{cluster}$) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster, return the top K words from this mean vector\n",
    "\n",
    "# Top K Words ($\\mu_{cluster} - \\mu_{complement}$ ) of Each Cluster\n",
    "compute the mean tf-idf vector of the cluster and also of the complement of the cluster,  \n",
    "take the difference mu_cluster - mu_complement, return the top K words in this difference\n",
    "\n",
    "# Most Relevant Opinion of Each Cluster\n",
    "compute the mean tf-idf vector, return the document in the cluster closet to the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 1 Summary (3851 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3851, 3)\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[1]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_walk + \"cluster_1.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dalton v. Jennings</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89374/da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Windsor v. McVeigh</td>\n",
       "      <td>1876-12-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89375/wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bigelow v. Berkshire Life Ins. Co.</td>\n",
       "      <td>1876-12-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89376/bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Indianapolis &amp; St. Louis R. Co. v. Horst</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89378/in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The\" Atlas\"</td>\n",
       "      <td>1876-11-27</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89379/th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     names       dates  \\\n",
       "0           0                        Dalton v. Jennings  1876-12-18   \n",
       "1           1                        Windsor v. McVeigh  1876-12-11   \n",
       "2           2        Bigelow v. Berkshire Life Ins. Co.  1876-12-11   \n",
       "3           3  Indianapolis & St. Louis R. Co. v. Horst  1876-12-18   \n",
       "4           4                               The\" Atlas\"  1876-11-27   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/89374/da...  \n",
       "1  https://www.courtlistener.com/opinion/89375/wi...  \n",
       "2  https://www.courtlistener.com/opinion/89376/bi...  \n",
       "3  https://www.courtlistener.com/opinion/89378/in...  \n",
       "4  https://www.courtlistener.com/opinion/89379/th...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_walk + 'cluster_1.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[1], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[1], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[1], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_walk + \"cluster_1_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guam</td>\n",
       "      <td>court</td>\n",
       "      <td>ยง</td>\n",
       "      <td>96819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wenzel</td>\n",
       "      <td>state</td>\n",
       "      <td>feder</td>\n",
       "      <td>96819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fslic</td>\n",
       "      <td>v</td>\n",
       "      <td>congress</td>\n",
       "      <td>96819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>artwar</td>\n",
       "      <td>ยง</td>\n",
       "      <td>act</td>\n",
       "      <td>96819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bail</td>\n",
       "      <td>act</td>\n",
       "      <td>commiss</td>\n",
       "      <td>96819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0      guam               court                   ยง          96819\n",
       "1           1    wenzel               state               feder          96819\n",
       "2           2     fslic                   v            congress          96819\n",
       "3           3    artwar                   ยง                 act          96819\n",
       "4           4      bail                 act             commiss          96819"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_walk + 'cluster_1_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 2 Summary (2640 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2640, 3)\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[2]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_walk + \"cluster_2.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hamilton v. Alabama</td>\n",
       "      <td>1961-11-13</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106300/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hoyt v. Florida</td>\n",
       "      <td>1961-11-20</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106302/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hodges v. United States</td>\n",
       "      <td>1961-12-04</td>\n",
       "      <td>https://www.courtlistener.com/opinion/106305/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Alaska Packers Assn. v. Pillsbury</td>\n",
       "      <td>1937-04-26</td>\n",
       "      <td>https://www.courtlistener.com/opinion/102813/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bradshaw v. Stumpf</td>\n",
       "      <td>2005-06-13</td>\n",
       "      <td>https://www.courtlistener.com/opinion/799973/b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              names       dates  \\\n",
       "0           0                Hamilton v. Alabama  1961-11-13   \n",
       "1           1                    Hoyt v. Florida  1961-11-20   \n",
       "2           2            Hodges v. United States  1961-12-04   \n",
       "3           3  Alaska Packers Assn. v. Pillsbury  1937-04-26   \n",
       "4           4                 Bradshaw v. Stumpf  2005-06-13   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/106300/h...  \n",
       "1  https://www.courtlistener.com/opinion/106302/h...  \n",
       "2  https://www.courtlistener.com/opinion/106305/h...  \n",
       "3  https://www.courtlistener.com/opinion/102813/a...  \n",
       "4  https://www.courtlistener.com/opinion/799973/b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_walk + 'cluster_2.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[2], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[2], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[2], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_walk + \"cluster_2_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>baal</td>\n",
       "      <td>court</td>\n",
       "      <td>sentenc</td>\n",
       "      <td>108329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>stumpf</td>\n",
       "      <td>state</td>\n",
       "      <td>convict</td>\n",
       "      <td>108329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>passport</td>\n",
       "      <td>v</td>\n",
       "      <td>trial</td>\n",
       "      <td>108329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lagrand</td>\n",
       "      <td>petition</td>\n",
       "      <td>juri</td>\n",
       "      <td>108329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ree</td>\n",
       "      <td>sct</td>\n",
       "      <td>petition</td>\n",
       "      <td>108329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0      baal               court             sentenc         108329\n",
       "1           1    stumpf               state             convict         108329\n",
       "2           2  passport                   v               trial         108329\n",
       "3           3   lagrand            petition                juri         108329\n",
       "4           4       ree                 sct            petition         108329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_walk + 'cluster_2_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 5 Summary (1996 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 3)\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[5]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_walk + \"cluster_5.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Windsor v. McVeigh</td>\n",
       "      <td>1876-12-11</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89375/wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>California Medical Assn. v. Federal Election C...</td>\n",
       "      <td>1981-06-26</td>\n",
       "      <td>https://www.courtlistener.com/opinion/110551/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kilbourn v. Thompson</td>\n",
       "      <td>1881-02-28</td>\n",
       "      <td>https://www.courtlistener.com/opinion/90311/ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hawke v. Smith (No. 1)</td>\n",
       "      <td>1920-06-01</td>\n",
       "      <td>https://www.courtlistener.com/opinion/99607/ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Regents of Univ. of Mich. v. Ewing</td>\n",
       "      <td>1985-12-12</td>\n",
       "      <td>https://www.courtlistener.com/opinion/111549/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              names       dates  \\\n",
       "0           0                                 Windsor v. McVeigh  1876-12-11   \n",
       "1           1  California Medical Assn. v. Federal Election C...  1981-06-26   \n",
       "2           2                               Kilbourn v. Thompson  1881-02-28   \n",
       "3           3                             Hawke v. Smith (No. 1)  1920-06-01   \n",
       "4           4                 Regents of Univ. of Mich. v. Ewing  1985-12-12   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/89375/wi...  \n",
       "1  https://www.courtlistener.com/opinion/110551/c...  \n",
       "2  https://www.courtlistener.com/opinion/90311/ki...  \n",
       "3  https://www.courtlistener.com/opinion/99607/ha...  \n",
       "4  https://www.courtlistener.com/opinion/111549/r...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_walk + 'cluster_5.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[5], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[5], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[5], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[5], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_walk + \"cluster_5_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lesag</td>\n",
       "      <td>court</td>\n",
       "      <td>led2d</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anastaplo</td>\n",
       "      <td>state</td>\n",
       "      <td>sct</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>church</td>\n",
       "      <td>v</td>\n",
       "      <td>school</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>flag</td>\n",
       "      <td>sct</td>\n",
       "      <td>us</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>communist</td>\n",
       "      <td>led2d</td>\n",
       "      <td>speech</td>\n",
       "      <td>104135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  top_words top_words_from_mean top_words_from_diff  \\\n",
       "0           0      lesag               court               led2d   \n",
       "1           1  anastaplo               state                 sct   \n",
       "2           2     church                   v              school   \n",
       "3           3       flag                 sct                  us   \n",
       "4           4  communist               led2d              speech   \n",
       "\n",
       "   most_relev_op  \n",
       "0         104135  \n",
       "1         104135  \n",
       "2         104135  \n",
       "3         104135  \n",
       "4         104135  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_walk + 'cluster_5_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 3 Summary (1494 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1494, 3)\n",
      "Wall time: 859 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[3]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_walk + \"cluster_3.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Barkley v. Levee Commissioners</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89372/ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Broughton v. Pensacola</td>\n",
       "      <td>1876-12-18</td>\n",
       "      <td>https://www.courtlistener.com/opinion/89373/br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Atlantic Coast Line R. Co. v. Mazursky</td>\n",
       "      <td>1910-02-21</td>\n",
       "      <td>https://www.courtlistener.com/opinion/97158/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>King v. West Virginia</td>\n",
       "      <td>1910-01-31</td>\n",
       "      <td>https://www.courtlistener.com/opinion/97154/ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston v. Southwestern Bell Telephone Co.</td>\n",
       "      <td>1922-05-29</td>\n",
       "      <td>https://www.courtlistener.com/opinion/100015/h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       names       dates  \\\n",
       "0           0              Barkley v. Levee Commissioners  1876-12-18   \n",
       "1           1                      Broughton v. Pensacola  1876-12-18   \n",
       "2           2      Atlantic Coast Line R. Co. v. Mazursky  1910-02-21   \n",
       "3           3                       King v. West Virginia  1910-01-31   \n",
       "4           4  Houston v. Southwestern Bell Telephone Co.  1922-05-29   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/89372/ba...  \n",
       "1  https://www.courtlistener.com/opinion/89373/br...  \n",
       "2  https://www.courtlistener.com/opinion/97158/at...  \n",
       "3  https://www.courtlistener.com/opinion/97154/ki...  \n",
       "4  https://www.courtlistener.com/opinion/100015/h...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_walk + 'cluster_3.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[3], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[3], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[3], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_walk + \"cluster_3_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vetterlein</td>\n",
       "      <td>state</td>\n",
       "      <td>compani</td>\n",
       "      <td>95657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vaccin</td>\n",
       "      <td>court</td>\n",
       "      <td>citi</td>\n",
       "      <td>95657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>milk</td>\n",
       "      <td>compani</td>\n",
       "      <td>contract</td>\n",
       "      <td>95657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>vs</td>\n",
       "      <td>v</td>\n",
       "      <td>ct</td>\n",
       "      <td>95657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sewer</td>\n",
       "      <td>contract</td>\n",
       "      <td>ordin</td>\n",
       "      <td>95657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   top_words top_words_from_mean top_words_from_diff  \\\n",
       "0           0  vetterlein               state             compani   \n",
       "1           1      vaccin               court                citi   \n",
       "2           2        milk             compani            contract   \n",
       "3           3          vs                   v                  ct   \n",
       "4           4       sewer            contract               ordin   \n",
       "\n",
       "   most_relev_op  \n",
       "0          95657  \n",
       "1          95657  \n",
       "2          95657  \n",
       "3          95657  \n",
       "4          95657  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_walk + 'cluster_3_summary.csv')\n",
    "cluster_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 12 Summary (1103 opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103, 3)\n",
      "Wall time: 566 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "opinion_names = []\n",
    "opinion_dates = []\n",
    "opinion_links = []\n",
    "\n",
    "for i in dict_top_n_clusters[12]:\n",
    "    try:\n",
    "        with open(clusters_dir + i + \".json\") as data_file:\n",
    "            data = json.load(data_file)\n",
    "    except IOError:\n",
    "        pass\n",
    "        #name, date, link = case_info2(i)\n",
    "        #opinion_names.append(name)\n",
    "        #opinion_dates.append(date)\n",
    "        #opinion_links.append(link)\n",
    "        \n",
    "    name = data['case_name'].encode('utf-8')\n",
    "    date = data['date_filed'].encode('utf-8')\n",
    "    link = 'https://www.courtlistener.com' + data['absolute_url'].encode('utf-8')\n",
    "    \n",
    "    opinion_names.append(name)\n",
    "    opinion_dates.append(date)\n",
    "    opinion_links.append(link)\n",
    "    \n",
    "cluster_info = pd.DataFrame()\n",
    "cluster_info['names'] = opinion_names\n",
    "cluster_info['dates'] = opinion_dates\n",
    "cluster_info['url'] = opinion_links\n",
    "\n",
    "cluster_info.to_csv(csv_dir_walk + \"cluster_12.csv\")\n",
    "\n",
    "print cluster_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>names</th>\n",
       "      <th>dates</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alabama v. King &amp; Boozer</td>\n",
       "      <td>1941-11-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103545/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Curry v. United States</td>\n",
       "      <td>1941-11-10</td>\n",
       "      <td>https://www.courtlistener.com/opinion/103546/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pullman Co. v. Kansas Ex Rel. Coleman</td>\n",
       "      <td>1910-01-31</td>\n",
       "      <td>https://www.courtlistener.com/opinion/97151/pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Watson v. State Comptroller of NY</td>\n",
       "      <td>1920-11-15</td>\n",
       "      <td>https://www.courtlistener.com/opinion/99649/wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Greenough v. Tax Assessors of Newport</td>\n",
       "      <td>1947-06-09</td>\n",
       "      <td>https://www.courtlistener.com/opinion/104437/g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  names       dates  \\\n",
       "0           0               Alabama v. King & Boozer  1941-11-10   \n",
       "1           1                 Curry v. United States  1941-11-10   \n",
       "2           2  Pullman Co. v. Kansas Ex Rel. Coleman  1910-01-31   \n",
       "3           3      Watson v. State Comptroller of NY  1920-11-15   \n",
       "4           4  Greenough v. Tax Assessors of Newport  1947-06-09   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.courtlistener.com/opinion/103545/a...  \n",
       "1  https://www.courtlistener.com/opinion/103546/c...  \n",
       "2  https://www.courtlistener.com/opinion/97151/pu...  \n",
       "3  https://www.courtlistener.com/opinion/99649/wa...  \n",
       "4  https://www.courtlistener.com/opinion/104437/g...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_info = pd.read_csv(csv_dir_walk + 'cluster_12.csv')\n",
    "cluster_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=1000 # number of words to get\n",
    "\n",
    "top_words = top_k_words(dict_top_n_clusters[12], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_mean = top_k_words_from_mean_vector(dict_top_n_clusters[12], k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "top_words_from_diff = top_k_words_from_difference(dict_top_n_clusters[12], all_the_opinions, k, tfidf_matrix, op_id_to_bow_id, vocab)\n",
    "most_relev_op = document_closest_to_mean(dict_top_n_clusters[12], tfidf_matrix, op_id_to_bow_id)\n",
    "\n",
    "top_words = [x.encode('utf-8') for x in top_words]\n",
    "top_words_from_mean = [x.encode('utf-8') for x in top_words_from_mean]\n",
    "top_words_from_diff = [x.encode('utf-8') for x in top_words_from_diff]\n",
    "\n",
    "#print '\\x1b[1;31m' + \"Top K Words:\" + '\\x1b[0m', top_words\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster):\" + '\\x1b[0m', top_words_from_mean\n",
    "#print '\\x1b[1;31m' + \"Top K Words (Mu_Cluster - Mu_Complement):\" + '\\x1b[0m', top_words_from_diff\n",
    "#print '\\x1b[1;31m' + \"Most Relevent Opinion:\" + '\\x1b[0m', most_relev_op\n",
    "\n",
    "cluster_summary = pd.DataFrame()\n",
    "cluster_summary['top_words'] = top_words\n",
    "cluster_summary['top_words_from_mean'] = top_words_from_mean\n",
    "cluster_summary['top_words_from_diff'] = top_words_from_diff\n",
    "cluster_summary['most_relev_op'] = most_relev_op\n",
    "\n",
    "cluster_summary.to_csv(csv_dir_walk + \"cluster_12_summary.csv\")\n",
    "\n",
    "print cluster_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_words_from_mean</th>\n",
       "      <th>top_words_from_diff</th>\n",
       "      <th>most_relev_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>milk</td>\n",
       "      <td>tax</td>\n",
       "      <td>tax</td>\n",
       "      <td>88605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>boom</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "      <td>88605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ethanol</td>\n",
       "      <td>commerc</td>\n",
       "      <td>commerc</td>\n",
       "      <td>88605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>export</td>\n",
       "      <td>v</td>\n",
       "      <td>interst</td>\n",
       "      <td>88605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>interst</td>\n",
       "      <td>taxat</td>\n",
       "      <td>88605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 top_words top_words_from_mean top_words_from_diff  most_relev_op\n",
       "0           0      milk                 tax                 tax          88605\n",
       "1           1      boom               state               state          88605\n",
       "2           2   ethanol             commerc             commerc          88605\n",
       "3           3    export                   v             interst          88605\n",
       "4           4    shrimp             interst               taxat          88605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summary = pd.read_csv(csv_dir_walk + 'cluster_12_summary.csv')\n",
    "cluster_summary.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
